{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-08T04:22:33.819986Z",
     "start_time": "2025-09-08T04:18:01.599274Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!pip install git+https://github.com/HKUDS/LightRAG.git\n",
    "\n",
    "from lightrag import LightRAG\n",
    "from lightrag.llm.openai import openai_complete_if_cache\n",
    "from lightrag.kg.shared_storage import initialize_pipeline_status\n",
    "from lightrag.utils import EmbeddingFunc, setup_logger"
   ],
   "id": "cb2b294542bdaa4f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Running command git clone --filter=blob:none --quiet https://github.com/HKUDS/LightRAG.git 'C:\\Users\\sckwo\\AppData\\Local\\Temp\\pip-req-build-zoptu7oh'\n",
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/HKUDS/LightRAG.git\n",
      "  Cloning https://github.com/HKUDS/LightRAG.git to c:\\users\\sckwo\\appdata\\local\\temp\\pip-req-build-zoptu7oh\n",
      "  Resolved https://github.com/HKUDS/LightRAG.git to commit c87eb2cfcf096e2e421851a2679ddffe9a57d10b\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting aiohttp (from lightrag-hku==1.4.8)\n",
      "  Using cached aiohttp-3.12.15-cp312-cp312-win_amd64.whl.metadata (7.9 kB)\n",
      "Collecting configparser (from lightrag-hku==1.4.8)\n",
      "  Using cached configparser-7.2.0-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting dotenv (from lightrag-hku==1.4.8)\n",
      "  Using cached dotenv-0.9.9-py2.py3-none-any.whl.metadata (279 bytes)\n",
      "Collecting future (from lightrag-hku==1.4.8)\n",
      "  Using cached future-1.0.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting json_repair (from lightrag-hku==1.4.8)\n",
      "  Downloading json_repair-0.50.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting nano-vectordb (from lightrag-hku==1.4.8)\n",
      "  Using cached nano_vectordb-0.0.4.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting networkx (from lightrag-hku==1.4.8)\n",
      "  Using cached networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting numpy (from lightrag-hku==1.4.8)\n",
      "  Using cached numpy-2.3.2-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting pandas>=2.0.0 (from lightrag-hku==1.4.8)\n",
      "  Using cached pandas-2.3.2-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Collecting pipmaster (from lightrag-hku==1.4.8)\n",
      "  Downloading pipmaster-1.0.4-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pydantic (from lightrag-hku==1.4.8)\n",
      "  Using cached pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Collecting pypinyin (from lightrag-hku==1.4.8)\n",
      "  Using cached pypinyin-0.55.0-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting python-dotenv (from lightrag-hku==1.4.8)\n",
      "  Using cached python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sckwo\\pycharmprojects\\graph-builder\\.venv\\lib\\site-packages (from lightrag-hku==1.4.8) (80.9.0)\n",
      "Collecting tenacity (from lightrag-hku==1.4.8)\n",
      "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting tiktoken (from lightrag-hku==1.4.8)\n",
      "  Using cached tiktoken-0.11.0-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting xlsxwriter>=3.1.0 (from lightrag-hku==1.4.8)\n",
      "  Using cached xlsxwriter-3.2.5-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\sckwo\\pycharmprojects\\graph-builder\\.venv\\lib\\site-packages (from pandas>=2.0.0->lightrag-hku==1.4.8) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas>=2.0.0->lightrag-hku==1.4.8)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas>=2.0.0->lightrag-hku==1.4.8)\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp->lightrag-hku==1.4.8)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp->lightrag-hku==1.4.8)\n",
      "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\sckwo\\pycharmprojects\\graph-builder\\.venv\\lib\\site-packages (from aiohttp->lightrag-hku==1.4.8) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->lightrag-hku==1.4.8)\n",
      "  Using cached frozenlist-1.7.0-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->lightrag-hku==1.4.8)\n",
      "  Using cached multidict-6.6.4-cp312-cp312-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->lightrag-hku==1.4.8)\n",
      "  Using cached propcache-0.3.2-cp312-cp312-win_amd64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->lightrag-hku==1.4.8)\n",
      "  Using cached yarl-1.20.1-cp312-cp312-win_amd64.whl.metadata (76 kB)\n",
      "Requirement already satisfied: packaging>=21.0 in c:\\users\\sckwo\\pycharmprojects\\graph-builder\\.venv\\lib\\site-packages (from pipmaster->lightrag-hku==1.4.8) (25.0)\n",
      "Collecting ascii_colors>=0.8.0 (from pipmaster->lightrag-hku==1.4.8)\n",
      "  Using cached ascii_colors-0.11.4-py3-none-any.whl.metadata (37 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic->lightrag-hku==1.4.8)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic->lightrag-hku==1.4.8)\n",
      "  Using cached pydantic_core-2.33.2-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\sckwo\\pycharmprojects\\graph-builder\\.venv\\lib\\site-packages (from pydantic->lightrag-hku==1.4.8) (4.15.0)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic->lightrag-hku==1.4.8)\n",
      "  Using cached typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken->lightrag-hku==1.4.8)\n",
      "  Downloading regex-2025.9.1-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\sckwo\\pycharmprojects\\graph-builder\\.venv\\lib\\site-packages (from tiktoken->lightrag-hku==1.4.8) (2.32.5)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\sckwo\\pycharmprojects\\graph-builder\\.venv\\lib\\site-packages (from ascii_colors>=0.8.0->pipmaster->lightrag-hku==1.4.8) (0.2.13)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\sckwo\\pycharmprojects\\graph-builder\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->lightrag-hku==1.4.8) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\sckwo\\pycharmprojects\\graph-builder\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken->lightrag-hku==1.4.8) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sckwo\\pycharmprojects\\graph-builder\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken->lightrag-hku==1.4.8) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sckwo\\pycharmprojects\\graph-builder\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken->lightrag-hku==1.4.8) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sckwo\\pycharmprojects\\graph-builder\\.venv\\lib\\site-packages (from requests>=2.26.0->tiktoken->lightrag-hku==1.4.8) (2025.8.3)\n",
      "Using cached pandas-2.3.2-cp312-cp312-win_amd64.whl (11.0 MB)\n",
      "Using cached numpy-2.3.2-cp312-cp312-win_amd64.whl (12.8 MB)\n",
      "Using cached xlsxwriter-3.2.5-py3-none-any.whl (172 kB)\n",
      "Using cached aiohttp-3.12.15-cp312-cp312-win_amd64.whl (450 kB)\n",
      "Using cached configparser-7.2.0-py3-none-any.whl (17 kB)\n",
      "Using cached dotenv-0.9.9-py2.py3-none-any.whl (1.9 kB)\n",
      "Using cached future-1.0.0-py3-none-any.whl (491 kB)\n",
      "Downloading json_repair-0.50.1-py3-none-any.whl (26 kB)\n",
      "Using cached nano_vectordb-0.0.4.3-py3-none-any.whl (5.6 kB)\n",
      "Using cached networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "Downloading pipmaster-1.0.4-py3-none-any.whl (26 kB)\n",
      "Using cached pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Using cached pydantic_core-2.33.2-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "Using cached pypinyin-0.55.0-py2.py3-none-any.whl (840 kB)\n",
      "Using cached python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Using cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Using cached tiktoken-0.11.0-cp312-cp312-win_amd64.whl (884 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached ascii_colors-0.11.4-py3-none-any.whl (71 kB)\n",
      "Using cached frozenlist-1.7.0-cp312-cp312-win_amd64.whl (43 kB)\n",
      "Using cached multidict-6.6.4-cp312-cp312-win_amd64.whl (46 kB)\n",
      "Using cached propcache-0.3.2-cp312-cp312-win_amd64.whl (41 kB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Downloading regex-2025.9.1-cp312-cp312-win_amd64.whl (275 kB)\n",
      "Using cached typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
      "Using cached yarl-1.20.1-cp312-cp312-win_amd64.whl (86 kB)\n",
      "Building wheels for collected packages: lightrag-hku\n",
      "  Building wheel for lightrag-hku (pyproject.toml): started\n",
      "  Building wheel for lightrag-hku (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for lightrag-hku: filename=lightrag_hku-1.4.8-py3-none-any.whl size=2667394 sha256=136ff5b062ad0a68052d1a2b95a7030315dbf7f808536d1d571cc9441da1dcfb\n",
      "  Stored in directory: C:\\Users\\sckwo\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-phsix8ig\\wheels\\3e\\5d\\d7\\2bd1dd2f453b4a2d49f27348ccf07da987ddba23b3b4a0c476\n",
      "Successfully built lightrag-hku\n",
      "Installing collected packages: pytz, xlsxwriter, tzdata, typing-inspection, tenacity, regex, python-dotenv, pypinyin, pydantic-core, propcache, numpy, networkx, multidict, json_repair, future, frozenlist, configparser, ascii_colors, annotated-types, aiohappyeyeballs, yarl, tiktoken, pydantic, pipmaster, pandas, nano-vectordb, dotenv, aiosignal, aiohttp, lightrag-hku\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiosignal-1.4.0 annotated-types-0.7.0 ascii_colors-0.11.4 configparser-7.2.0 dotenv-0.9.9 frozenlist-1.7.0 future-1.0.0 json_repair-0.50.1 lightrag-hku-1.4.8 multidict-6.6.4 nano-vectordb-0.0.4.3 networkx-3.5 numpy-2.3.2 pandas-2.3.2 pipmaster-1.0.4 propcache-0.3.2 pydantic-2.11.7 pydantic-core-2.33.2 pypinyin-0.55.0 python-dotenv-1.1.1 pytz-2025.2 regex-2025.9.1 tenacity-9.1.2 tiktoken-0.11.0 typing-inspection-0.4.1 tzdata-2025.2 xlsxwriter-3.2.5 yarl-1.20.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[94m2025-09-08 11:21:50 - pipmaster.package_manager - INFO - Executing: C:\\Users\\sckwo\\PycharmProjects\\Graph-Builder\\.venv\\Scripts\\python.exe -m pip install --upgrade openai\u001B[0m\n",
      "\u001B[94m2025-09-08 11:22:32 - pipmaster.package_manager - INFO - Command succeeded: C:\\Users\\sckwo\\PycharmProjects\\Graph-Builder\\.venv\\Scripts\\python.exe -m pip install --upgrade openai\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "1bc74c25-e530-42bc-88c1-e34b3993826f",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# Устанавливаем все нужные пакеты за один раз\n",
    "!pip install spacy pymorphy3 tqdm nltk torch transformers openai\n",
    "\n",
    "import codecs\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import asyncio\n",
    "\n",
    "import nest_asyncio\n",
    "from typing import List\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import codecs\n",
    "import copy\n",
    "import json\n",
    "from typing import Dict, List, Tuple\n",
    "import warnings\n",
    "\n",
    "import spacy\n",
    "from pymorphy3 import MorphAnalyzer\n",
    "from pymorphy3.analyzer import Parse\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0e1d24af-edd2-4b3c-b762-61aed35b2ecb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T05:16:12.327594Z",
     "start_time": "2025-08-20T05:16:12.312748Z"
    }
   },
   "source": [
    "RANDOM_SEED = 42\n",
    "random.seed(RANDOM_SEED)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "724661c3-5fc6-40e7-9ceb-c5850b09ad77",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T05:16:13.519084Z",
     "start_time": "2025-08-20T05:16:13.494802Z"
    }
   },
   "source": [
    "dataset_dir = 'pages_txt'\n",
    "print(f'os.path.isdir({dataset_dir}) = {os.path.isdir(dataset_dir)}')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "os.path.isdir(pages_txt) = True\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "510562b7-57f7-459f-97a0-9ffa97345455",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T03:51:31.966507Z",
     "start_time": "2025-08-20T03:51:31.943929Z"
    }
   },
   "source": [
    "text_files = list(map(lambda it2: os.path.join(dataset_dir, it2), filter(lambda it1: it1.endswith('.txt'), os.listdir(dataset_dir))))"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T04:22:43.913850Z",
     "start_time": "2025-08-20T04:22:43.820872Z"
    }
   },
   "cell_type": "code",
   "source": [
    "POS_DICT: Dict[str, str] = {\n",
    "    'NOUN': 'NOUN',\n",
    "    'PROPN': 'NOUN',\n",
    "    'PRON': 'NPRO',\n",
    "    'DET': 'NPRO',\n",
    "    'ADJ': 'ADJF',\n",
    "    'VERB': 'VERB',\n",
    "    'AUX': 'PRCL',\n",
    "    'PART': 'PRCL',\n",
    "    'ADV': 'ADVB',\n",
    "    'NUM': 'NUMR',\n",
    "    'ADP': 'PREP',\n",
    "    'CCONJ': 'CONJ',\n",
    "    'SCONJ': 'CONJ',\n",
    "    'INTJ': 'INTJ'\n",
    "}\n",
    "\n",
    "CASE_DICT: Dict[str, str] = {\n",
    "    'Acc': 'accs',\n",
    "    'Dat': 'datv',\n",
    "    'Gen': 'gent',\n",
    "    'Ins': 'ablt',\n",
    "    'Loc': 'loct',\n",
    "    'Nom': 'nomn',\n",
    "    'Par': 'gen2',\n",
    "    'Voc': 'voct'\n",
    "}\n",
    "\n",
    "NUMBER_DICT: Dict[str, str] = {\n",
    "    'Sing': 'sing',\n",
    "    'Plur': 'plur'\n",
    "}\n",
    "\n",
    "\n",
    "def initialize_abbreviation_subsystem(config_name: str) -> (\n",
    "        Tuple)[Dict[str, Tuple[List[str], List[Tuple[str, str, str]]]], spacy.Language, MorphAnalyzer]:\n",
    "    nlp = spacy.load('ru_core_news_sm')\n",
    "    analyzer = MorphAnalyzer()\n",
    "    with codecs.open(config_name, mode='r', encoding='utf-8', errors='ignore') as fp:\n",
    "        data = json.load(fp)\n",
    "    if not isinstance(data, dict):\n",
    "        err_msg = f'The abbreviation config \"{config_name}\" contains a wrong information!'\n",
    "        raise ValueError(err_msg)\n",
    "    keys = list(data.keys())\n",
    "    abbr = dict()\n",
    "    for k in keys:\n",
    "        if not isinstance(k, str):\n",
    "            err_msg = f'The abbreviation config \"{config_name}\" contains a wrong information!'\n",
    "            raise ValueError(err_msg)\n",
    "        if not k.isalpha():\n",
    "            err_msg = f'The abbreviation config \"{config_name}\" contains a wrong information!'\n",
    "            raise ValueError(err_msg)\n",
    "        if not isinstance(data[k], str):\n",
    "            err_msg = f'The abbreviation config \"{config_name}\" contains a wrong information!'\n",
    "            raise ValueError(err_msg)\n",
    "        v = data[k].strip()\n",
    "        if len(v) == 0:\n",
    "            err_msg = f'The abbreviation config \"{config_name}\" contains a wrong information!'\n",
    "            raise ValueError(err_msg)\n",
    "        doc = nlp(v)\n",
    "        tokens = []\n",
    "        morpho_data = []\n",
    "        for token in doc:\n",
    "            tokens.append(token.text)\n",
    "            if str(token.pos_) in POS_DICT:\n",
    "                pos = POS_DICT[str(token.pos_)]\n",
    "            else:\n",
    "                pos = str(token.pos_)\n",
    "            case = token.morph.get('Case')\n",
    "            if len(case) > 0:\n",
    "                if len(case[0]) > 0:\n",
    "                    case = CASE_DICT[str(case[0])]\n",
    "                else:\n",
    "                    case = ''\n",
    "            else:\n",
    "                case = ''\n",
    "            number = token.morph.get('Number')\n",
    "            if len(number) > 0:\n",
    "                if len(number[0]) > 0:\n",
    "                    number = NUMBER_DICT[str(number[0])]\n",
    "                else:\n",
    "                    number = ''\n",
    "            else:\n",
    "                number = ''\n",
    "            morpho_data.append((pos, case, number))\n",
    "        abbr[k.lower()] = (tokens, morpho_data)\n",
    "        del doc, tokens, morpho_data\n",
    "    return abbr, nlp, analyzer\n",
    "\n",
    "\n",
    "def tokenize_and_analyze_morphology(text: str, nlp: spacy.Language) -> (\n",
    "        Tuple)[List[str], List[Tuple[int, int]], List[Tuple[str, str, str]]]:\n",
    "    doc = nlp(text)\n",
    "    all_tokens = []\n",
    "    all_bounds = []\n",
    "    all_morpho = []\n",
    "    for token in doc:\n",
    "        all_tokens.append(token.text)\n",
    "        all_bounds.append((token.idx, token.idx + len(token)))\n",
    "        pos = POS_DICT.get(str(token.pos_), str(token.pos_))\n",
    "        case = token.morph.get('Case')\n",
    "        if len(case) > 0:\n",
    "            if len(case[0]) > 0:\n",
    "                case = CASE_DICT[str(case[0])]\n",
    "                if case == 'accs':\n",
    "                    case = 'loct'\n",
    "            else:\n",
    "                case = ''\n",
    "        else:\n",
    "            case = ''\n",
    "        number = token.morph.get('Number')\n",
    "        if len(number) > 0:\n",
    "            if len(number[0]) > 0:\n",
    "                number = NUMBER_DICT[str(number[0])]\n",
    "            else:\n",
    "                number = ''\n",
    "        else:\n",
    "            number = ''\n",
    "        all_morpho.append((pos, case, number))\n",
    "    del doc\n",
    "    return all_tokens, all_bounds, all_morpho\n",
    "\n",
    "\n",
    "def find_main_token(phrase_tokens: List[str], morpho: List[Tuple[str, str, str]]) -> int:\n",
    "    found_idx = -1\n",
    "    n = len(phrase_tokens)\n",
    "    if n != len(morpho):\n",
    "        err_msg = (f'Number of tokens does not equal to number of morphological items! '\n",
    "                   f'{phrase_tokens} != {morpho}')\n",
    "        raise ValueError(err_msg)\n",
    "    for idx in range(n):\n",
    "        if (morpho[idx][0] in {'NOUN', 'NPRO'}) and (morpho[idx][1] == 'nomn'):\n",
    "            found_idx = idx\n",
    "    return found_idx\n",
    "\n",
    "\n",
    "def find_form(token: str, morpho: Tuple[str, str, str], analyzer: MorphAnalyzer) -> Parse:\n",
    "    variants = analyzer.parse(token)\n",
    "    best = variants[0]\n",
    "    for it in variants[1:]:\n",
    "        if it.tag.POS == morpho[0] and (morpho[2] in {'sing', 'plur'} and it.tag.number == morpho[2]):\n",
    "            best = it\n",
    "    return best\n",
    "\n",
    "\n",
    "def inflect_phrase(phrase_tokens: List[str], morpho: List[Tuple[str, str, str]], inflector: MorphAnalyzer,\n",
    "                   target_case: str, target_number: str) -> str:\n",
    "    main_token_idx = find_main_token(phrase_tokens, morpho)\n",
    "    if main_token_idx < 0:\n",
    "        warnings.warn(f'The text \"{\" \".join(phrase_tokens)}\" cannot be inflected!')\n",
    "        return ' '.join(phrase_tokens)\n",
    "    inflected_tokens = []\n",
    "    for idx, val in enumerate(phrase_tokens):\n",
    "        if idx <= main_token_idx:\n",
    "            # Исключаем пустые значения\n",
    "            target_grammemes = set()\n",
    "            if target_case:\n",
    "                target_grammemes.add(target_case)\n",
    "            if target_number:\n",
    "                target_grammemes.add(target_number)\n",
    "\n",
    "            inflection = find_form(val, morpho[idx], inflector).inflect(target_grammemes)\n",
    "            if inflection is None:\n",
    "                inflected_tokens.append(val)\n",
    "            else:\n",
    "                inflected_tokens.append(inflection.word)\n",
    "        else:\n",
    "            inflected_tokens.append(val)\n",
    "    if len(inflected_tokens) == 0:\n",
    "        return ''\n",
    "    if inflected_tokens[0][0].islower():\n",
    "        inflected_tokens[0] = inflected_tokens[0][0].upper() + inflected_tokens[0][1:]\n",
    "    return ' '.join(inflected_tokens)\n",
    "\n",
    "\n",
    "def replace_abbreviations(old_text: str, abbreviation_config: Dict[str, Tuple[List[str], List[Tuple[str, str, str]]]],\n",
    "                          nlp: spacy.Language, morph: MorphAnalyzer) -> str:\n",
    "    tokens, bounds, morpho_data = tokenize_and_analyze_morphology(old_text, nlp)\n",
    "    new_text = copy.copy(old_text)\n",
    "    for idx, (token, (pos, case, number)) in enumerate(zip(tokens, morpho_data)):\n",
    "        if token.lower() in abbreviation_config:\n",
    "            case = case if case in CASE_DICT.values() else ''\n",
    "            number = number if number in NUMBER_DICT.values() else ''\n",
    "            new_token = inflect_phrase(\n",
    "                abbreviation_config[token.lower()][0],\n",
    "                abbreviation_config[token.lower()][1],\n",
    "                morph,\n",
    "                case,\n",
    "                number\n",
    "            )\n",
    "            new_text = new_text[:bounds[idx][0]] + new_token + new_text[bounds[idx][1]:]\n",
    "            if len(new_token) != len(token):\n",
    "                bounds[idx] = (\n",
    "                    bounds[idx][0],\n",
    "                    bounds[idx][1] + len(new_token) - len(token)\n",
    "                )\n",
    "                for other_idx in range(idx + 1, len(bounds)):\n",
    "                    bounds[other_idx] = (\n",
    "                        bounds[other_idx][0] + len(new_token) - len(token),\n",
    "                        bounds[other_idx][1] + len(new_token) - len(token)\n",
    "                    )\n",
    "    return new_text\n"
   ],
   "id": "f68d455fea5d0e2d",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T04:23:10.642295Z",
     "start_time": "2025-08-20T04:22:50.340633Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# python -m spacy download ru_core_news_sm\n",
    "config_fname = os.path.join('full_abbreviations_updated.json')\n",
    "config, spacy, pymorphy = initialize_abbreviation_subsystem(config_fname)\n",
    "\n",
    "def convert(text: str) -> str:\n",
    "    return replace_abbreviations(text, config, spacy, pymorphy)\n"
   ],
   "id": "be12a96b45f0754b",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T04:26:05.989910Z",
     "start_time": "2025-08-20T04:23:25.559670Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text_data = []\n",
    "for cur_fname in text_files:\n",
    "    with codecs.open(cur_fname, mode='r', encoding='utf-8', errors='ignore') as fp:\n",
    "        new_text = '\\n'.join(list(map(\n",
    "            lambda it3: ' '.join(it3.replace('\\r', ' ').split()),\n",
    "            filter(\n",
    "                lambda it2: len(it2) > 0,\n",
    "                map(\n",
    "                    lambda it1: it1.strip(),\n",
    "                    fp.readlines()\n",
    "                )\n",
    "            )\n",
    "        ))).strip()\n",
    "    if len(new_text) > 0:\n",
    "        text_data.append(convert(new_text))\n",
    "    del new_text"
   ],
   "id": "a60ff995-63be-41cf-a556-a08a8d9141cc",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sckwo\\AppData\\Local\\Temp\\ipykernel_6384\\3072762628.py:160: UserWarning: The text \"механико - математический факультет\" cannot be inflected!\n",
      "  warnings.warn(f'The text \"{\" \".join(phrase_tokens)}\" cannot be inflected!')\n",
      "C:\\Users\\sckwo\\AppData\\Local\\Temp\\ipykernel_6384\\3072762628.py:160: UserWarning: The text \"Open Researcher and Contributor ID\" cannot be inflected!\n",
      "  warnings.warn(f'The text \"{\" \".join(phrase_tokens)}\" cannot be inflected!')\n",
      "C:\\Users\\sckwo\\AppData\\Local\\Temp\\ipykernel_6384\\3072762628.py:160: UserWarning: The text \"федеральный государственный образовательный стандарт\" cannot be inflected!\n",
      "  warnings.warn(f'The text \"{\" \".join(phrase_tokens)}\" cannot be inflected!')\n"
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "id": "638415f9-8805-4a3a-a274-38ec58c25599",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T04:26:48.008143Z",
     "start_time": "2025-08-20T04:26:48.000814Z"
    }
   },
   "source": [
    "print(f'Number of documents is {len(text_data)}.')\n",
    "print(f'3 random documents:')\n",
    "for it in random.sample(text_data, 3):\n",
    "    print('\\n' + it)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents is 473.\n",
      "3 random documents:\n",
      "\n",
      "Инструкция Программное обеспечение рассылке о сверке кадровых данных\n",
      "Письмо с уведомлением о сверке кадровых данных получают пользователи, которые работают с документом Проект штатного расписания конкретной кафедры, и начальники Учебного - методического объединения факультета/института – Институтам математики в письме сообщается о проблемах Программное обеспечение всем кафедрам. В письме указан только номер задачи, конкретные проблемы можно увидеть только открыв саму задачу в 1С:Учебный процесс.\n",
      "Если вам на почту пришло письмо с уведомлением, что необходимо произвести сверку кадровых данных, нужно сделать следующее:\n",
      "1. Необходимо зайти в 1С:Учебный процесс в раздел «Текущие дела» - Мои задачи:\n",
      "2. Если у вас нет такого блока на «Рабочем столе» в системе 1С: Учебный процесс, то его можно добавить. Для этого зайдите в «Главное меню» (кнопка в виде стрелки вниз на верхней кнопочной панели) – Вид – Настройка рабочего стола.\n",
      "3. Далее в открывшемся окне «Настройка рабочего стола» в колонке «Доступные формы» выбрать «Текущие дела: Форма» и переместить при помощи кнопки «Добавить» сначала в «Левую колонку для рабочего стола», затем при помощи кнопки в виде стрелки в «Правую колонку рабочего стола». Нажать кнопку «ОК».\n",
      "4. В данном разделе «Текущие дела перейти в «Мои задачи». В открывшемся окне «Мои задачи» открыть задачу (кликнуть Программное обеспечение ней два раза левой клавишей мыши). В задаче содержится описание: Программное обеспечение какой кафедре, Программное обеспечение какому сотруднику необходимо сверить кадровые данные.\n",
      "5. Зайти в последний документ проект ШР и сравнить на соответствие поля «Должность», «Ученая степень», «Вид занятости» Программное обеспечение указанным в задаче сотрудникам.\n",
      "6. Если у сотрудника отличаются данные, то в текущем проекте ШР кликнуть Программное обеспечение кнопке «Создать на основании – Корректировка Программное обеспечение кадровой истории». Обратите внимание на дату нового документа, возможно ее надо будет изменить. В новом документе ПШР будут отражены изменения Программное обеспечение кадровым данным за исключением информации Программное обеспечение виду занятости. Вид занятости необходимо самостоятельно изменить в этом документе. Провести документ. В результате корректировки кадровых данных может измениться ФОТ.\n",
      "7. Проверить ‒ если все данные Программное обеспечение сотрудникам соответствуют кадровым – вернуться в задачу и нажать на кнопку «Выполнено». Сообщить начальнику Учебного - методического объединения о выполнении сверки.\n",
      "После того как вы проставите отметку «Выполнено» ‒ данная задача не будет приходить как напоминание к вам на почту и уйдет из списка задач. В случае необходимости, чтобы ее заново просмотреть, проставьте отметку внизу окна «Мои задачи» - «Показать выполненные». Начальник Учебного - методического объединения тоже должен проставить отметку о выполнении задачи. Если начальник Учебного - методического объединения считает, что это не должно входить в его обязанности, и он не хочет получать такие сообщения, необходимо сообщить об этом письмом на техподдержку (4141@ nsu.ru: http://nsu.ru/).: http://nsu.ru/ Секретари кафедр, которые работают только с документом «Распределение поручений» и не имеют доступа проекту ШР, также могут написать письмо на: http://nsu.ru/ 4141@nsu.ru. Такие пользователи будут исключены из списка тех, кому приходят напоминания.\n",
      "\n",
      "Столовая\n",
      "О сервисе\n",
      "1С:Общепит предназначен для автоматизации оперативного, бухгалтерского и налогового учета на предприятиях общественного питания.\n",
      "Для кого\n",
      "Сотрудник\n",
      "Работа с сервисом\n",
      "Аккаунт\n",
      "Вход в систему можно выполнить только под логином/паролем для 1С. Для доступа в 1С необходимо использовать логин вида: имя_пользователя@jupiter.nsu.ru или JUPITER\\имя_пользователя. Получить/восстановить аккаунт в 1С можно написав на 4141@nsu.ru или support@nsu.ru.\n",
      "Инструкции\n",
      "* 1С Столовая (общепит): https://help.nsu.ru/pages/viewpage.action?pageId=35653577&src=contextnavpagetreemode\n",
      "* Работа с заявками из Ресторана: https://help.nsu.ru/pages/viewpage.action?pageId=78708747\n",
      "\n",
      "Инструкция Программное обеспечение настройке L2TP_IPsec VPN подключения _macOS_\n",
      "На примере macOS High Sierra (10.13)\n",
      "Дальнейшая инструкция написана с учётом того, что Вы создаёте подключение вручную с нуля.\n",
      "Если же Вам прислан файл готовой конфигурации VPN Новосибирского государственного университета, то достаточно выполнить только пункты 4,5,6,8 данной инструкции. То есть нужно будет только добавить свой логин и пароль от универсальной учётной записи Новосибирского государственного университета, как в примерах приведённых на иллюстрациях. А также в меню Advanced (Дополнительно) поставить галку Send all traffic over VPN Connection (Отправлять весь трафик через VPN).\n",
      "Остальные настройки уже будут в шаблоне.\n",
      "1.Итак, сперва заходим в настройки сети System Preferences / Network:\n",
      "2. В настройках сети следует нажать кнопку с символом \"+\", чтобы создать новую службу.\n",
      "3. Будет выведен диалог выбора основных параметров службы:\n",
      "1) В поле Interface (Интерфейс) нужно выбрать значение VPN.\n",
      "2) Затем в поле VPN Type (Тип VPN) нужно указать \"L2TP через IPSec\"\n",
      "3) Для поля Service Name (Имя службы) можно придумать и ввести любое понятное Вам название. Например NSU-VPN(L2TP)\n",
      "4. Программное обеспечение нажатии кнопки Create (Создать) в левой части окна \"Сеть\" появится созданная служба, а справа откроется окно конфигурации службы.\n",
      "В нем нужно указать в поле Server address (Адрес сервера) имя сервера - gw5.nsu.ru: http://gw5.nsu.ru.\n",
      "В поле Account Name (Имя учетной записи) необходимо ввести Ваш универсальный логин Новосибирский государственный университет, он же почтовый адрес. К примеру vasyapupkin@post.nsu.ru.\n",
      "А также рекомендуется поставить галочку Show VPN status in menu bar (Показывать статус VPN в строке меню),\n",
      "чтобы появился значок VPN и меню для подключения в правом верхнем углу рабочего стола.\n",
      "5. Затем требуется настроить также и параметры аутентификации. Для перехода к ним нужно нажать кнопку Authentication settings (Настройки аутентификации).\n",
      "6. Откроется окно c выбранными Программное обеспечение умолчанию опциями Password(Пароль) и Shared Secret(Общий ключ). В первое поле нужно ввести пароль своей учетной записи Новосибирского государственного университета (он же пароль от почты),\n",
      "а в поле \" Общий ключ (Shared Secret) \" нужно ввести общий ключ IPSec, высланный Вам Программное обеспечение заявке на подключение.\n",
      "Если же вы не заводили подключение вручную, а применили высланную Вам готовую конфигурацию VPN Новосибирский государственный университет ключ уже будет вбит и вводить его не нужно.\n",
      "\"Имя группы\" указывать не требуется. Программное обеспечение нажатию кнопки \"OK\" окно настройки аутентификации будет закрыто.\n",
      "7. Далее нажмите кнопку Advanced (Дополнительно).\n",
      "8. В открывшемся окне на закладке Options (Параметры) нужно включить опцию Send all traffic over VPN Connection (Отправлять весь трафик через VPN)\n",
      "и нажать кнопку \"OK\". Остальные настройки на этой и других вкладках в меню Advanced (Дополнительно) менять не требуется.\n",
      "9. Не забудьте нажать на кнопку Apply (Применить), чтобы сохранить все настройки. И подключение готово, можно пользоваться.\n",
      "Нажав на connect из этого меню или справа вверху рабочего стола, что удобнее.\n",
      "Время соединения она учитывает, не забывайте отключаться когда перестаёте работать с ресурсами Новосибирского государственного университета предоставляемыми этим удалённым доступом.\n",
      "Также не стоит качать при включённом соединении VPN какие-то большие файлы не из сети Новосибирского государственного университета, торренты, фильмы, развлекательные ресурсы и тому подобное.\n",
      "Так как пока VPN включён весь Ваш интернет-трафик идёт через Новосибирском государственном университете, а не только трафик с ресурсов Новосибирского государственного университета, что может снизить скорость и существенно затруднить работу Ваших коллег.\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "id": "8fd50501-8609-4403-aab1-0ef41f12b76e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T04:27:01.609724Z",
     "start_time": "2025-08-20T04:27:01.588473Z"
    }
   },
   "source": [
    "from tqdm.auto import tqdm\n",
    "special_tokens = dict()\n",
    "re_for_special_tokens = re.compile(r'\\[\\w+?\\]')\n",
    "for cur_text in tqdm(text_data):\n",
    "    start_pos = 0\n",
    "    search_res = re_for_special_tokens.search(cur_text[start_pos:])\n",
    "    while search_res is not None:\n",
    "        token_start = start_pos + search_res.start()\n",
    "        token_end = start_pos + search_res.end()\n",
    "        new_special_token = cur_text[token_start:token_end] \n",
    "        special_tokens[new_special_token] = special_tokens.get(new_special_token, 0) + 1\n",
    "        start_pos = token_end\n",
    "        search_res = re_for_special_tokens.search(cur_text[start_pos:])\n",
    "special_token_keys = sorted(list(special_tokens.keys()), key=lambda it: (-special_tokens[it], it))\n",
    "print(f'There are {len(special_tokens)} special tokens. They are:')\n",
    "for it in special_token_keys:\n",
    "    print('{0:>20}: {1:>6}'.format(it, special_tokens[it]))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 473/473 [00:00<00:00, 152385.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 special tokens. They are:\n",
      "             [CACHE]:      2\n",
      "          [MASSMAIL]:      1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "id": "110ad144-0af3-4efd-ad51-54525bcf47c8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T04:27:18.470327Z",
     "start_time": "2025-08-20T04:27:18.461785Z"
    }
   },
   "source": "setup_logger(\"lightrag\", level=\"INFO\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "id": "03e91ed8-26a9-4a84-b1ed-b0c9caf007a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T04:27:21.217066Z",
     "start_time": "2025-08-20T04:27:21.130189Z"
    }
   },
   "source": [
    "WORKING_DIR = 'prepared_it_new'\n",
    "if not os.path.exists(WORKING_DIR):\n",
    "    os.mkdir(WORKING_DIR)"
   ],
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mIndexError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[39]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[43mtexts_with_port_range\u001B[49m\u001B[43m[\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m]\u001B[49m)\n",
      "\u001B[31mIndexError\u001B[39m: list index out of range"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "id": "55d9e37d-b5fa-4eb6-916d-88b355b25117",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T05:17:55.326618Z",
     "start_time": "2025-08-20T05:17:55.318777Z"
    }
   },
   "source": [
    "VLLM_API_KEY = ''\n",
    "VLLM_BASE_URL = 'everest.nsu.ru:9111'\n",
    "os.environ['OPENAI_API_KEY'] = VLLM_API_KEY"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "f3ce5884-e299-4c3a-a644-abd016eaafac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T05:17:54.143088Z",
     "start_time": "2025-08-20T05:17:54.124533Z"
    }
   },
   "source": [
    "LLM_NAME = 'RuadaptQwen3-32B-Instruct'\n",
    "TEMPERATURE = 0.3\n",
    "QUERY_MAX_TOKENS = 8000"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "52498d08-e2bb-49f5-84e9-7f3838950a1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T05:28:32.746768Z",
     "start_time": "2025-08-20T05:28:32.739702Z"
    }
   },
   "source": [
    "LOCAL_EMBEDDER_DIMENSION = 768\n",
    "LOCAL_EMBEDDER_MAX_TOKENS = 4096\n",
    "LOCAL_EMBEDDER_NAME = '/workspace/data/models/gte-multilingual-base'\n",
    "print(f'os.path.isdir({LOCAL_EMBEDDER_NAME}) = {os.path.isdir(LOCAL_EMBEDDER_NAME)}')"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "id": "959ad61a-af5a-41ac-9c40-71ee98885803",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T05:17:50.456878Z",
     "start_time": "2025-08-20T05:17:50.437200Z"
    }
   },
   "source": [
    "ABBREVIATIONS_FNAME = 'full_abbreviations_updated.json'\n",
    "print(f'os.path.isfile({ABBREVIATIONS_FNAME}) = {os.path.isfile(ABBREVIATIONS_FNAME)}')"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "23a731a1-534e-4ef3-b7f3-ac0722689e07",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T05:17:49.179078Z",
     "start_time": "2025-08-20T05:17:49.159263Z"
    }
   },
   "source": [
    "TEMPLATE_FOR_ABBREVIATION_EXPLAINING = '''Отредактируйте, пожалуйста, текст заданного документа так, чтобы этот документ стал более простым и понятным для обычных людей от юных старшеклассников до пожилых мужчин и женщин. При этом не надо, пожалуйста, применять markdown или иной вид гипертекста. Главное, на что вам надо обратить внимание и по возможности исправить - это логика изложения и понятность формулировок документа. Ничего не объясняйте и не комментируйте своё решение, просто перепишите текст документа.\n",
    "\n",
    "Обратите внимание, что документ анонимизирован, то есть все именованные сущности заменены специальными словами-масками в квадратных скобках (например, вместо текста \"Иван Иванович Иванов любит горчицу\" вы встретите текст \"[NAME] любит горчицу\"). Полный список специальных слов-масок приведён здесь: {special_masks}. Не изменяйте этих слов, пожалуйста, а оставляйте как есть.\n",
    "\n",
    "Также исправьте грамматические ошибки в тексте документа, если они там есть. Кроме того, если вы обнаружите аббревиатуры в тексте этого документа, то замените все обнаруженные аббревиатуры их корректными расшифровками, сохранив морфологическую и синтаксическую согласованность. Вот здесь вы можете ознакомиться с JSON-словарём, описывающим возможные аббревиатуры и их расшифровки:\n",
    "\n",
    "```json\n",
    "{abbreviations_dict}\n",
    "```\n",
    "\n",
    "Далее приведён текст документа, нуждающийся в возможном улучшении:\n",
    "\n",
    "```text\n",
    "{text_of_document}\n",
    "```'''"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "os.path.isdir(C:\\Users\\sckwo\\models\\gte-multilingual-base) = True\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "aa0fb77c-811b-4bab-86af-2538f39e5f44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T05:17:47.428258Z",
     "start_time": "2025-08-20T05:17:47.414001Z"
    }
   },
   "source": [
    "async def llm_model_func(\n",
    "    prompt, system_prompt=None, history_messages=[], keyword_extraction=False, **kwargs\n",
    ") -> str:\n",
    "    return await openai_complete_if_cache(\n",
    "        LLM_NAME,\n",
    "        prompt,\n",
    "        system_prompt=system_prompt,\n",
    "        history_messages=history_messages,\n",
    "        api_key=VLLM_API_KEY,\n",
    "        base_url=VLLM_BASE_URL,\n",
    "        temperature=TEMPERATURE,\n",
    "        **kwargs\n",
    "    )"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "os.path.isfile(full_abbreviations_updated.json) = True\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "a2a4cfe4-e86d-4046-946a-ae93417aa457",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T05:18:00.414630Z",
     "start_time": "2025-08-20T05:18:00.405088Z"
    }
   },
   "source": [
    "async def gte_hf_embed(texts: List[str], tokenizer, embed_model) -> np.ndarray:\n",
    "    device = next(embed_model.parameters()).device\n",
    "    encoded_texts = tokenizer(\n",
    "        texts, return_tensors='pt', padding=True, truncation=True\n",
    "    ).to(device)\n",
    "    batch_dict = tokenizer(\n",
    "        texts, return_tensors='pt',\n",
    "        max_length=LOCAL_EMBEDDER_MAX_TOKENS, padding=True, truncation=True,\n",
    "    ).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = embed_model(**batch_dict)\n",
    "        embeddings = F.normalize(\n",
    "            outputs.last_hidden_state[:, 0][:LOCAL_EMBEDDER_DIMENSION],\n",
    "            p=2, dim=1\n",
    "        )\n",
    "    if embeddings.dtype == torch.bfloat16:\n",
    "        return embeddings.detach().to(torch.float32).cpu().numpy()\n",
    "    else:\n",
    "        return embeddings.detach().cpu().numpy()"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "3c3e1186-5124-401b-98e3-53320eb1dfde",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T05:18:03.469217Z",
     "start_time": "2025-08-20T05:18:03.450387Z"
    }
   },
   "source": [
    "def explain_abbreviations_with_llm(document: str, abbreviations: dict) -> str:\n",
    "    snow_stemmer = SnowballStemmer(language='russian')\n",
    "    filtered_abbreviations = dict()\n",
    "    for cur_word in nltk.wordpunct_tokenize(document):\n",
    "        if cur_word in abbreviations:\n",
    "            filtered_abbreviations[cur_word] = abbreviations[cur_word]\n",
    "        elif cur_word.lower() in abbreviations:\n",
    "            filtered_abbreviations[cur_word] = abbreviations[cur_word.lower()]\n",
    "        elif cur_word.upper() in abbreviations:\n",
    "            filtered_abbreviations[cur_word] = abbreviations[cur_word.upper()]\n",
    "        else:\n",
    "            stem = snow_stemmer.stem(cur_word)\n",
    "            if stem in abbreviations:\n",
    "                filtered_abbreviations[cur_word] = abbreviations[stem]\n",
    "            elif stem.lower() in abbreviations:\n",
    "                filtered_abbreviations[cur_word] = abbreviations[stem.lower()]\n",
    "            elif stem.upper() in abbreviations:\n",
    "                filtered_abbreviations[cur_word] = abbreviations[stem.upper()]\n",
    "    del snow_stemmer\n",
    "    if len(filtered_abbreviations) == 0:\n",
    "        return document\n",
    "    user_prompt = TEMPLATE_FOR_ABBREVIATION_EXPLAINING.format(\n",
    "        abbreviations_dict=filtered_abbreviations,\n",
    "        text_of_document=document,\n",
    "        special_masks=special_token_keys\n",
    "    )\n",
    "    messages = [{'role': 'user', 'content': user_prompt}]\n",
    "    global client\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=LLM_NAME,\n",
    "            messages=messages,\n",
    "            temperature=TEMPERATURE,\n",
    "            n=1,\n",
    "            max_tokens=QUERY_MAX_TOKENS\n",
    "        )\n",
    "        new_improved_document = response.choices[0].message.content\n",
    "        del response\n",
    "    except:\n",
    "        new_improved_document = document\n",
    "    del messages, user_prompt\n",
    "    return new_improved_document"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "04d277ae-142d-4087-9288-b2c8d8dbde4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T05:18:05.143505Z",
     "start_time": "2025-08-20T05:18:05.128605Z"
    }
   },
   "source": [
    "async def initialize_rag():\n",
    "    emb_tokenizer = AutoTokenizer.from_pretrained(\n",
    "        LOCAL_EMBEDDER_NAME\n",
    "    )\n",
    "    emb_model = AutoModel.from_pretrained(\n",
    "        LOCAL_EMBEDDER_NAME,\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    emb_model.eval()\n",
    "    \n",
    "    rag = LightRAG(\n",
    "        working_dir=WORKING_DIR,\n",
    "        llm_model_func=llm_model_func,\n",
    "        cosine_better_than_threshold=0.1,\n",
    "        embedding_func=EmbeddingFunc(\n",
    "            embedding_dim=LOCAL_EMBEDDER_DIMENSION,\n",
    "            max_token_size=LOCAL_EMBEDDER_MAX_TOKENS,\n",
    "            func=lambda texts: gte_hf_embed(\n",
    "                texts,\n",
    "                tokenizer=emb_tokenizer,\n",
    "                embed_model=emb_model\n",
    "            )\n",
    "        ),\n",
    "        addon_params={'language': 'Russian'},\n",
    "    )\n",
    "\n",
    "    await rag.initialize_storages()\n",
    "    await initialize_pipeline_status()\n",
    "\n",
    "    return rag"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "65e67e48-675f-40d9-84a5-21de79097a3d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T05:18:07.148219Z",
     "start_time": "2025-08-20T05:18:07.137001Z"
    }
   },
   "source": [
    "client = OpenAI(\n",
    "    api_key=VLLM_API_KEY,\n",
    "    base_url=VLLM_BASE_URL,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "ab6e870c-ab27-4c29-b272-55b1ff917189",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T05:18:09.990046Z",
     "start_time": "2025-08-20T05:18:09.982002Z"
    }
   },
   "source": "MAX_NUMBER_OF_TEXTS = None",
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "id": "2dff3b67-070e-4766-ae4d-b2aa1144e5c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T05:18:13.526132Z",
     "start_time": "2025-08-20T05:18:12.928563Z"
    }
   },
   "source": [
    "improved_texts_fname = os.path.join(WORKING_DIR, 'improved_texts.json')\n",
    "\n",
    "if os.path.isfile(improved_texts_fname):\n",
    "    with open(improved_texts_fname, mode='r', encoding='utf-8') as fp:\n",
    "        improved_texts = json.load(fp)\n",
    "\n",
    "# data_iter = text_data if MAX_NUMBER_OF_TEXTS is None else text_data[:MAX_NUMBER_OF_TEXTS]\n",
    "# # improved_texts = [convert(cur_text) for cur_text in tqdm(data_iter)]\n",
    "# for cur_text in tqdm(data_iter):\n",
    "#     improved_texts.append(convert(cur_text))\n",
    "#\n",
    "# with open(improved_texts_fname, mode='w', encoding='utf-8') as fp:\n",
    "#     json.dump(improved_texts, fp, ensure_ascii=False, indent=4)\n"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "ee0ae7b8-cf2c-4959-ae81-65d2934fc9bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T05:18:14.887695Z",
     "start_time": "2025-08-20T05:18:14.872580Z"
    }
   },
   "source": [
    "with codecs.open(improved_texts_fname, mode='w', encoding='utf-8') as fp:\n",
    "    json.dump(fp=fp, obj=improved_texts, ensure_ascii=False, indent=4)"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "id": "8ed52086-f534-4c58-8acb-8efc31eb3b7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T05:19:12.513750Z",
     "start_time": "2025-08-20T05:19:12.446434Z"
    }
   },
   "source": [
    "print(f'3 random examples of improved texts:')\n",
    "if MAX_NUMBER_OF_TEXTS is None:\n",
    "    selected_indices = random.sample(list(range(len(text_data))), 3)\n",
    "else:\n",
    "    selected_indices = random.sample(list(range(len(text_data[0:MAX_NUMBER_OF_TEXTS]))), 3)\n",
    "for example_index in selected_indices:\n",
    "    print('')\n",
    "    print('BEFORE IMPROVING:')\n",
    "    print(' '.join(text_data[example_index].split()))\n",
    "    print('AFTER IMPROVING:')\n",
    "    print(' '.join(improved_texts[example_index].split()))"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "4b28878b-59d5-44d0-9593-7f4157222d32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-13T10:59:09.123122Z",
     "start_time": "2025-08-13T10:59:09.108694Z"
    }
   },
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "nest_asyncio.apply()\n",
    "rag = asyncio.run(initialize_rag())\n",
    "if MAX_NUMBER_OF_TEXTS is None:\n",
    "    for cur_text in tqdm(improved_texts):\n",
    "        rag.insert(cur_text)\n",
    "else:\n",
    "    for cur_text in tqdm(improved_texts[0:MAX_NUMBER_OF_TEXTS]):\n",
    "        rag.insert(cur_text)\n",
    "rag.finalize_storages()"
   ],
   "outputs": [],
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "id": "b7f9d792-5617-4c59-9bfe-24e10d0d25a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-20T05:26:35.756462Z",
     "start_time": "2025-08-20T05:26:03.211017Z"
    }
   },
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "nest_asyncio.apply()\n",
    "rag = asyncio.run(initialize_rag())\n",
    "if MAX_NUMBER_OF_TEXTS is None:\n",
    "    for cur_text in tqdm(improved_texts):\n",
    "        rag.insert(cur_text)\n",
    "else:\n",
    "    for cur_text in tqdm(improved_texts[0:MAX_NUMBER_OF_TEXTS]):\n",
    "        rag.insert(cur_text)\n",
    "rag.finalize_storages()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at C:\\Users\\sckwo\\models\\gte-multilingual-base were not used when initializing NewModel: ['classifier.bias', 'classifier.weight']\n",
      "- This IS expected if you are initializing NewModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing NewModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "INFO: [_] Created new empty graph fiel: prepared_it_new_2\\graph_chunk_entity_relation.graphml\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 768, 'metric': 'cosine', 'storage_file': 'prepared_it_new_2\\\\vdb_entities.json'} 0 data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 768, 'metric': 'cosine', 'storage_file': 'prepared_it_new_2\\\\vdb_relationships.json'} 0 data\n",
      "INFO:nano-vectordb:Init {'embedding_dim': 768, 'metric': 'cosine', 'storage_file': 'prepared_it_new_2\\\\vdb_chunks.json'} 0 data\n",
      "WARNING: Rerank is enabled but no rerank_model_func provided. Reranking will be skipped.\n",
      "\n",
      "\n",
      "  0%|          | 0/584 [00:00<?, ?it/s]\u001B[A\u001B[AINFO: Stored 1 new unique documents\n",
      "INFO: Processing 1 document(s)\n",
      "INFO: Extracting stage 1/1: unknown_source\n",
      "INFO: Processing d-id: doc-6fc48dd67af8fa351b9cded3e934f63f\n",
      "INFO: limit_async: 8 new workers initialized\n",
      "INFO: limit_async: 4 new workers initialized\n",
      "ERROR: OpenAI API Call Failed,\n",
      "Model: openai/gpt-4.1,\n",
      "Params: {'temperature': 0.3}, Got: Error code: 400 - {'error': {'message': 'User with this API key not found', 'code': 400}}\n",
      "ERROR: limit_async: Error in decorated function: Error code: 400 - {'error': {'message': 'User with this API key not found', 'code': 400}}\n",
      "ERROR: Failed to extract entities and relationships: Error code: 400 - {'error': {'message': 'User with this API key not found', 'code': 400}}\n",
      "ERROR: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sckwo\\PycharmProjects\\light_rag_db\\.venv\\Lib\\site-packages\\lightrag\\lightrag.py\", line 1336, in process_document\n",
      "    await entity_relation_task\n",
      "  File \"C:\\Users\\sckwo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"C:\\Users\\sckwo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\tasks.py\", line 375, in __wakeup\n",
      "    future.result()\n",
      "  File \"C:\\Users\\sckwo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\sckwo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\tasks.py\", line 304, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sckwo\\PycharmProjects\\light_rag_db\\.venv\\Lib\\site-packages\\lightrag\\lightrag.py\", line 1563, in _process_entity_relation_graph\n",
      "    raise e\n",
      "  File \"C:\\Users\\sckwo\\PycharmProjects\\light_rag_db\\.venv\\Lib\\site-packages\\lightrag\\lightrag.py\", line 1548, in _process_entity_relation_graph\n",
      "    chunk_results = await extract_entities(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sckwo\\PycharmProjects\\light_rag_db\\.venv\\Lib\\site-packages\\lightrag\\operate.py\", line 1707, in extract_entities\n",
      "    raise task.exception()\n",
      "  File \"C:\\Users\\sckwo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\tasks.py\", line 306, in __step_run_and_handle_result\n",
      "    result = coro.throw(exc)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sckwo\\PycharmProjects\\light_rag_db\\.venv\\Lib\\site-packages\\lightrag\\operate.py\", line 1683, in _process_with_semaphore\n",
      "    return await _process_single_content(chunk)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sckwo\\PycharmProjects\\light_rag_db\\.venv\\Lib\\site-packages\\lightrag\\operate.py\", line 1592, in _process_single_content\n",
      "    final_result = await use_llm_func_with_cache(\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sckwo\\PycharmProjects\\light_rag_db\\.venv\\Lib\\site-packages\\lightrag\\utils.py\", line 1437, in use_llm_func_with_cache\n",
      "    res: str = await use_llm_func(input_text, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sckwo\\PycharmProjects\\light_rag_db\\.venv\\Lib\\site-packages\\lightrag\\utils.py\", line 581, in wait_func\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sckwo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"C:\\Users\\sckwo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\tasks.py\", line 375, in __wakeup\n",
      "    future.result()\n",
      "  File \"C:\\Users\\sckwo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\sckwo\\PycharmProjects\\light_rag_db\\.venv\\Lib\\site-packages\\lightrag\\utils.py\", line 365, in worker\n",
      "    result = await func(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sckwo\\AppData\\Local\\Temp\\ipykernel_13412\\3262575834.py\", line 4, in llm_model_func\n",
      "    return await openai_complete_if_cache(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sckwo\\PycharmProjects\\light_rag_db\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sckwo\\PycharmProjects\\light_rag_db\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sckwo\\PycharmProjects\\light_rag_db\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sckwo\\PycharmProjects\\light_rag_db\\.venv\\Lib\\site-packages\\tenacity\\_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sckwo\\PycharmProjects\\light_rag_db\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 400, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sckwo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sckwo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"C:\\Users\\sckwo\\PycharmProjects\\light_rag_db\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sckwo\\PycharmProjects\\light_rag_db\\.venv\\Lib\\site-packages\\lightrag\\llm\\openai.py\", line 188, in openai_complete_if_cache\n",
      "    response = await openai_async_client.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sckwo\\PycharmProjects\\light_rag_db\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 2589, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sckwo\\PycharmProjects\\light_rag_db\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sckwo\\PycharmProjects\\light_rag_db\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': 'User with this API key not found', 'code': 400}}\n",
      "\n",
      "ERROR: Failed to extract document 1/1: unknown_source\n",
      "INFO: Document processing pipeline completed\n",
      "\n",
      "\n",
      "  0%|          | 1/584 [00:12<2:02:30, 12.61s/it]\u001B[A\u001B[AINFO: Stored 1 new unique documents\n",
      "INFO: Processing 2 document(s)\n",
      "INFO: Extracting stage 1/2: unknown_source\n",
      "INFO: Processing d-id: doc-6fc48dd67af8fa351b9cded3e934f63f\n",
      "INFO: Extracting stage 2/2: unknown_source\n",
      "INFO: Processing d-id: doc-7ce9b807657b091d0f6d44cecf24dc85\n",
      "Exception ignored in: <function tqdm.__del__ at 0x0000021484DB0360>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sckwo\\PycharmProjects\\light_rag_db\\.venv\\Lib\\site-packages\\tqdm\\std.py\", line 1148, in __del__\n",
      "    self.close()\n",
      "  File \"C:\\Users\\sckwo\\PycharmProjects\\light_rag_db\\.venv\\Lib\\site-packages\\tqdm\\notebook.py\", line 279, in close\n",
      "    self.disp(bar_style='danger', check_delay=False)\n",
      "    ^^^^^^^^^\n",
      "AttributeError: 'tqdm_notebook' object has no attribute 'disp'\n",
      "  0%|          | 1/584 [00:15<2:31:14, 15.57s/it]\n",
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x00000214838ED940>>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sckwo\\PycharmProjects\\light_rag_db\\.venv\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 796, in _clean_thread_parent_frames\n",
      "    active_threads = {thread.ident for thread in threading.enumerate()}\n",
      "                                                 ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sckwo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\threading.py\", line 1513, in enumerate\n",
      "    def enumerate():\n",
      "    \n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[23]\u001B[39m\u001B[32m, line 7\u001B[39m\n\u001B[32m      5\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m MAX_NUMBER_OF_TEXTS \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m      6\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m cur_text \u001B[38;5;129;01min\u001B[39;00m tqdm(improved_texts):\n\u001B[32m----> \u001B[39m\u001B[32m7\u001B[39m         \u001B[43mrag\u001B[49m\u001B[43m.\u001B[49m\u001B[43minsert\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcur_text\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m      8\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m      9\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m cur_text \u001B[38;5;129;01min\u001B[39;00m tqdm(improved_texts[\u001B[32m0\u001B[39m:MAX_NUMBER_OF_TEXTS]):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\light_rag_db\\.venv\\Lib\\site-packages\\lightrag\\lightrag.py:840\u001B[39m, in \u001B[36mLightRAG.insert\u001B[39m\u001B[34m(self, input, split_by_character, split_by_character_only, ids, file_paths, track_id)\u001B[39m\n\u001B[32m    824\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"Sync Insert documents with checkpoint support\u001B[39;00m\n\u001B[32m    825\u001B[39m \n\u001B[32m    826\u001B[39m \u001B[33;03mArgs:\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    837\u001B[39m \u001B[33;03m    str: tracking ID for monitoring processing status\u001B[39;00m\n\u001B[32m    838\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    839\u001B[39m loop = always_get_an_event_loop()\n\u001B[32m--> \u001B[39m\u001B[32m840\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mloop\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun_until_complete\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    841\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mainsert\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    842\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    843\u001B[39m \u001B[43m        \u001B[49m\u001B[43msplit_by_character\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    844\u001B[39m \u001B[43m        \u001B[49m\u001B[43msplit_by_character_only\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    845\u001B[39m \u001B[43m        \u001B[49m\u001B[43mids\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    846\u001B[39m \u001B[43m        \u001B[49m\u001B[43mfile_paths\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    847\u001B[39m \u001B[43m        \u001B[49m\u001B[43mtrack_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    848\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    849\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\light_rag_db\\.venv\\Lib\\site-packages\\nest_asyncio.py:92\u001B[39m, in \u001B[36m_patch_loop.<locals>.run_until_complete\u001B[39m\u001B[34m(self, future)\u001B[39m\n\u001B[32m     90\u001B[39m     f._log_destroy_pending = \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m     91\u001B[39m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m f.done():\n\u001B[32m---> \u001B[39m\u001B[32m92\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_run_once\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     93\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._stopping:\n\u001B[32m     94\u001B[39m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\light_rag_db\\.venv\\Lib\\site-packages\\nest_asyncio.py:133\u001B[39m, in \u001B[36m_patch_loop.<locals>._run_once\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    130\u001B[39m curr_task = curr_tasks.pop(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[32m    132\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m133\u001B[39m     \u001B[43mhandle\u001B[49m\u001B[43m.\u001B[49m\u001B[43m_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    134\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    135\u001B[39m     \u001B[38;5;66;03m# restore the current task\u001B[39;00m\n\u001B[32m    136\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m curr_task \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\events.py:84\u001B[39m, in \u001B[36mHandle._run\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m     82\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_run\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m     83\u001B[39m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m84\u001B[39m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_context\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_callback\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_args\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     85\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mSystemExit\u001B[39;00m, \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m):\n\u001B[32m     86\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\tasks.py:386\u001B[39m, in \u001B[36mTask.__wakeup\u001B[39m\u001B[34m(self, future)\u001B[39m\n\u001B[32m    378\u001B[39m     \u001B[38;5;28mself\u001B[39m.__step(exc)\n\u001B[32m    379\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    380\u001B[39m     \u001B[38;5;66;03m# Don't pass the value of `future.result()` explicitly,\u001B[39;00m\n\u001B[32m    381\u001B[39m     \u001B[38;5;66;03m# as `Future.__iter__` and `Future.__await__` don't need it.\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    384\u001B[39m     \u001B[38;5;66;03m# instead of `__next__()`, which is slower for futures\u001B[39;00m\n\u001B[32m    385\u001B[39m     \u001B[38;5;66;03m# that return non-generator iterators from their `__iter__`.\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m386\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m__step\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    387\u001B[39m \u001B[38;5;28mself\u001B[39m = \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\tasks.py:293\u001B[39m, in \u001B[36mTask.__step\u001B[39m\u001B[34m(self, exc)\u001B[39m\n\u001B[32m    291\u001B[39m _enter_task(\u001B[38;5;28mself\u001B[39m._loop, \u001B[38;5;28mself\u001B[39m)\n\u001B[32m    292\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m293\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m__step_run_and_handle_result\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    294\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    295\u001B[39m     _leave_task(\u001B[38;5;28mself\u001B[39m._loop, \u001B[38;5;28mself\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\tasks.py:304\u001B[39m, in \u001B[36mTask.__step_run_and_handle_result\u001B[39m\u001B[34m(***failed resolving arguments***)\u001B[39m\n\u001B[32m    300\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    301\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m exc \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    302\u001B[39m         \u001B[38;5;66;03m# We use the `send` method directly, because coroutines\u001B[39;00m\n\u001B[32m    303\u001B[39m         \u001B[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m304\u001B[39m         result = \u001B[43mcoro\u001B[49m\u001B[43m.\u001B[49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[32m    305\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    306\u001B[39m         result = coro.throw(exc)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\light_rag_db\\.venv\\Lib\\site-packages\\lightrag\\utils.py:365\u001B[39m, in \u001B[36mpriority_limit_async_func_call.<locals>.final_decro.<locals>.worker\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m    361\u001B[39m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n\u001B[32m    363\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    364\u001B[39m     \u001B[38;5;66;03m# Execute function\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m365\u001B[39m     result = \u001B[38;5;28;01mawait\u001B[39;00m func(*args, **kwargs)\n\u001B[32m    366\u001B[39m     \u001B[38;5;66;03m# If future is not done, set the result\u001B[39;00m\n\u001B[32m    367\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m future.done():\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\light_rag_db\\.venv\\Lib\\site-packages\\lightrag\\utils.py:248\u001B[39m, in \u001B[36mEmbeddingFunc.__call__\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m    247\u001B[39m \u001B[38;5;28;01masync\u001B[39;00m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, *args, **kwargs) -> np.ndarray:\n\u001B[32m--> \u001B[39m\u001B[32m248\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mawait\u001B[39;00m \u001B[38;5;28mself\u001B[39m.func(*args, **kwargs)\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[12]\u001B[39m\u001B[32m, line 11\u001B[39m, in \u001B[36mgte_hf_embed\u001B[39m\u001B[34m(texts, tokenizer, embed_model)\u001B[39m\n\u001B[32m      6\u001B[39m batch_dict = tokenizer(\n\u001B[32m      7\u001B[39m     texts, return_tensors=\u001B[33m'\u001B[39m\u001B[33mpt\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m      8\u001B[39m     max_length=LOCAL_EMBEDDER_MAX_TOKENS, padding=\u001B[38;5;28;01mTrue\u001B[39;00m, truncation=\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[32m      9\u001B[39m ).to(device)\n\u001B[32m     10\u001B[39m \u001B[38;5;28;01mwith\u001B[39;00m torch.no_grad():\n\u001B[32m---> \u001B[39m\u001B[32m11\u001B[39m     outputs = \u001B[43membed_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mbatch_dict\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     12\u001B[39m     embeddings = F.normalize(\n\u001B[32m     13\u001B[39m         outputs.last_hidden_state[:, \u001B[32m0\u001B[39m][:LOCAL_EMBEDDER_DIMENSION],\n\u001B[32m     14\u001B[39m         p=\u001B[32m2\u001B[39m, dim=\u001B[32m1\u001B[39m\n\u001B[32m     15\u001B[39m     )\n\u001B[32m     16\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m embeddings.dtype == torch.bfloat16:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\light_rag_db\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1771\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1772\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\light_rag_db\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1779\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1780\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1781\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1782\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1783\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1784\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1786\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1787\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.cache\\huggingface\\modules\\transformers_modules\\Alibaba-NLP\\new-impl\\40ced75c3017eb27626c9d4ea981bde21a2662f4\\modeling.py:940\u001B[39m, in \u001B[36mNewModel.forward\u001B[39m\u001B[34m(self, input_ids, attention_mask, length, subset_indices, token_type_ids, position_ids, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict, unpad_inputs)\u001B[39m\n\u001B[32m    930\u001B[39m     logger.warning_once(\u001B[33m\"\u001B[39m\u001B[33mTODO: logn_attention_scale\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    931\u001B[39m \u001B[38;5;66;03m#     # attention scale log_512(input_len)\u001B[39;00m\n\u001B[32m    932\u001B[39m \u001B[38;5;66;03m#     attention_scale = attention_mask.sum(1).log() / torch.tensor(self.config.max_position_embeddings).log()\u001B[39;00m\n\u001B[32m    933\u001B[39m \u001B[38;5;66;03m#     # inference-time logn scale need clip 1\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    937\u001B[39m \u001B[38;5;66;03m# else:\u001B[39;00m\n\u001B[32m    938\u001B[39m \u001B[38;5;66;03m#     attention_scale = None\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m940\u001B[39m encoder_outputs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mencoder\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    941\u001B[39m \u001B[43m    \u001B[49m\u001B[43membedding_output\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    942\u001B[39m \u001B[43m    \u001B[49m\u001B[43mattention_bias\u001B[49m\u001B[43m=\u001B[49m\u001B[43mattention_bias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    943\u001B[39m \u001B[43m    \u001B[49m\u001B[43mrope_embeds\u001B[49m\u001B[43m=\u001B[49m\u001B[43mrope_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    944\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpadding_inputs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpadding_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    945\u001B[39m \u001B[43m    \u001B[49m\u001B[43mattention_scale\u001B[49m\u001B[43m=\u001B[49m\u001B[43mattention_scale\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    946\u001B[39m \u001B[43m    \u001B[49m\u001B[43msubset_indices\u001B[49m\u001B[43m=\u001B[49m\u001B[43msubset_indices\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    947\u001B[39m \u001B[43m    \u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[43m=\u001B[49m\u001B[43mhead_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    948\u001B[39m \u001B[43m    \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m=\u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    949\u001B[39m \u001B[43m    \u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m=\u001B[49m\u001B[43moutput_hidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    950\u001B[39m \u001B[43m    \u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[43m=\u001B[49m\u001B[43mreturn_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    951\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    952\u001B[39m sequence_output = encoder_outputs[\u001B[32m0\u001B[39m]\n\u001B[32m    953\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m unpad_inputs \u001B[38;5;129;01mand\u001B[39;00m output_padded:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\light_rag_db\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1771\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1772\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\light_rag_db\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1779\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1780\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1781\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1782\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1783\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1784\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1786\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1787\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.cache\\huggingface\\modules\\transformers_modules\\Alibaba-NLP\\new-impl\\40ced75c3017eb27626c9d4ea981bde21a2662f4\\modeling.py:749\u001B[39m, in \u001B[36mNewEncoder.forward\u001B[39m\u001B[34m(self, hidden_states, attention_bias, rope_embeds, padding_inputs, attention_scale, subset_indices, head_mask, output_attentions, output_hidden_states, return_dict)\u001B[39m\n\u001B[32m    738\u001B[39m     layer_outputs = \u001B[38;5;28mself\u001B[39m._gradient_checkpointing_func(\n\u001B[32m    739\u001B[39m         layer_module.\u001B[34m__call__\u001B[39m,\n\u001B[32m    740\u001B[39m         hidden_states,\n\u001B[32m   (...)\u001B[39m\u001B[32m    746\u001B[39m         layer_head_mask,\n\u001B[32m    747\u001B[39m     )\n\u001B[32m    748\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m749\u001B[39m     layer_outputs = \u001B[43mlayer_module\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    750\u001B[39m \u001B[43m        \u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    751\u001B[39m \u001B[43m        \u001B[49m\u001B[43mattention_bias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    752\u001B[39m \u001B[43m        \u001B[49m\u001B[43mrope_embeds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    753\u001B[39m \u001B[43m        \u001B[49m\u001B[43mpadding_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    754\u001B[39m \u001B[43m        \u001B[49m\u001B[43mattention_scale\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    755\u001B[39m \u001B[43m        \u001B[49m\u001B[43mlayer_subset_indices\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    756\u001B[39m \u001B[43m        \u001B[49m\u001B[43mlayer_head_mask\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    757\u001B[39m \u001B[43m        \u001B[49m\u001B[43moutput_attentions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    758\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    760\u001B[39m hidden_states = layer_outputs[\u001B[32m0\u001B[39m]\n\u001B[32m    761\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m output_attentions:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\light_rag_db\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1771\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1772\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\light_rag_db\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1779\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1780\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1781\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1782\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1783\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1784\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1786\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1787\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.cache\\huggingface\\modules\\transformers_modules\\Alibaba-NLP\\new-impl\\40ced75c3017eb27626c9d4ea981bde21a2662f4\\modeling.py:692\u001B[39m, in \u001B[36mNewLayer.forward\u001B[39m\u001B[34m(self, hidden_states, attention_bias, rope_embeds, padding_inputs, attention_scale, subset_indices, head_mask, output_attentions, qkv_inputs)\u001B[39m\n\u001B[32m    690\u001B[39m \u001B[38;5;66;03m# Fully Connected\u001B[39;00m\n\u001B[32m    691\u001B[39m residual = hidden_states\n\u001B[32m--> \u001B[39m\u001B[32m692\u001B[39m hidden_states = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mmlp\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhidden_states\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    693\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.hidden_dropout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    694\u001B[39m     hidden_states = \u001B[38;5;28mself\u001B[39m.hidden_dropout(hidden_states)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\light_rag_db\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1771\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1772\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\light_rag_db\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1779\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1780\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1781\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1782\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1783\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1784\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1786\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1787\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\.cache\\huggingface\\modules\\transformers_modules\\Alibaba-NLP\\new-impl\\40ced75c3017eb27626c9d4ea981bde21a2662f4\\modeling.py:620\u001B[39m, in \u001B[36mNewGatedMLP.forward\u001B[39m\u001B[34m(self, hidden_states)\u001B[39m\n\u001B[32m    618\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.hidden_dropout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    619\u001B[39m     gated_states = \u001B[38;5;28mself\u001B[39m.hidden_dropout(gated_states)\n\u001B[32m--> \u001B[39m\u001B[32m620\u001B[39m down_states = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdown_proj\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgated_states\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    621\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m down_states\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\light_rag_db\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1771\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1772\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1773\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\light_rag_db\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1779\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1780\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1781\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1782\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1783\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1784\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1786\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1787\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\light_rag_db\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001B[39m, in \u001B[36mLinear.forward\u001B[39m\u001B[34m(self, input)\u001B[39m\n\u001B[32m    124\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) -> Tensor:\n\u001B[32m--> \u001B[39m\u001B[32m125\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[43m.\u001B[49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: limit_async: Creating 1 new workers\n",
      "ERROR: OpenAI API Call Failed,\n",
      "Model: openai/gpt-4.1,\n",
      "Params: {'temperature': 0.3}, Got: Error code: 400 - {'error': {'message': 'User with this API key not found', 'code': 400}}\n",
      "ERROR: limit_async: Error in decorated function: Error code: 400 - {'error': {'message': 'User with this API key not found', 'code': 400}}\n",
      "ERROR: Failed to extract entities and relationships: Error code: 400 - {'error': {'message': 'User with this API key not found', 'code': 400}}\n",
      "ERROR: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sckwo\\PycharmProjects\\light_rag_db\\.venv\\Lib\\site-packages\\lightrag\\lightrag.py\", line 1336, in process_document\n",
      "    await entity_relation_task\n",
      "  File \"C:\\Users\\sckwo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"C:\\Users\\sckwo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\tasks.py\", line 375, in __wakeup\n",
      "    future.result()\n",
      "  File \"C:\\Users\\sckwo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\sckwo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\tasks.py\", line 304, in __step_run_and_handle_result\n",
      "    result = coro.send(None)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sckwo\\PycharmProjects\\light_rag_db\\.venv\\Lib\\site-packages\\lightrag\\lightrag.py\", line 1563, in _process_entity_relation_graph\n",
      "    raise e\n",
      "  File \"C:\\Users\\sckwo\\PycharmProjects\\light_rag_db\\.venv\\Lib\\site-packages\\lightrag\\lightrag.py\", line 1548, in _process_entity_relation_graph\n",
      "    chunk_results = await extract_entities(\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sckwo\\PycharmProjects\\light_rag_db\\.venv\\Lib\\site-packages\\lightrag\\operate.py\", line 1707, in extract_entities\n",
      "    raise task.exception()\n",
      "  File \"C:\\Users\\sckwo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\tasks.py\", line 306, in __step_run_and_handle_result\n",
      "    result = coro.throw(exc)\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sckwo\\PycharmProjects\\light_rag_db\\.venv\\Lib\\site-packages\\lightrag\\operate.py\", line 1683, in _process_with_semaphore\n",
      "    return await _process_single_content(chunk)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sckwo\\PycharmProjects\\light_rag_db\\.venv\\Lib\\site-packages\\lightrag\\operate.py\", line 1592, in _process_single_content\n",
      "    final_result = await use_llm_func_with_cache(\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sckwo\\PycharmProjects\\light_rag_db\\.venv\\Lib\\site-packages\\lightrag\\utils.py\", line 1437, in use_llm_func_with_cache\n",
      "    res: str = await use_llm_func(input_text, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sckwo\\PycharmProjects\\light_rag_db\\.venv\\Lib\\site-packages\\lightrag\\utils.py\", line 581, in wait_func\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sckwo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\futures.py\", line 287, in __await__\n",
      "    yield self  # This tells Task to wait for completion.\n",
      "    ^^^^^^^^^^\n",
      "  File \"C:\\Users\\sckwo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\tasks.py\", line 375, in __wakeup\n",
      "    future.result()\n",
      "  File \"C:\\Users\\sckwo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\futures.py\", line 203, in result\n",
      "    raise self._exception.with_traceback(self._exception_tb)\n",
      "  File \"C:\\Users\\sckwo\\PycharmProjects\\light_rag_db\\.venv\\Lib\\site-packages\\lightrag\\utils.py\", line 365, in worker\n",
      "    result = await func(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sckwo\\AppData\\Local\\Temp\\ipykernel_13412\\3262575834.py\", line 4, in llm_model_func\n",
      "    return await openai_complete_if_cache(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sckwo\\PycharmProjects\\light_rag_db\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 189, in async_wrapped\n",
      "    return await copy(fn, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sckwo\\PycharmProjects\\light_rag_db\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 111, in __call__\n",
      "    do = await self.iter(retry_state=retry_state)\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sckwo\\PycharmProjects\\light_rag_db\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 153, in iter\n",
      "    result = await action(retry_state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sckwo\\PycharmProjects\\light_rag_db\\.venv\\Lib\\site-packages\\tenacity\\_utils.py\", line 99, in inner\n",
      "    return call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sckwo\\PycharmProjects\\light_rag_db\\.venv\\Lib\\site-packages\\tenacity\\__init__.py\", line 400, in <lambda>\n",
      "    self._add_action_func(lambda rs: rs.outcome.result())\n",
      "                                     ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sckwo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sckwo\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"C:\\Users\\sckwo\\PycharmProjects\\light_rag_db\\.venv\\Lib\\site-packages\\tenacity\\asyncio\\__init__.py\", line 114, in __call__\n",
      "    result = await fn(*args, **kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sckwo\\PycharmProjects\\light_rag_db\\.venv\\Lib\\site-packages\\lightrag\\llm\\openai.py\", line 188, in openai_complete_if_cache\n",
      "    response = await openai_async_client.chat.completions.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sckwo\\PycharmProjects\\light_rag_db\\.venv\\Lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 2589, in create\n",
      "    return await self._post(\n",
      "           ^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sckwo\\PycharmProjects\\light_rag_db\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1794, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\sckwo\\PycharmProjects\\light_rag_db\\.venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1594, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': 'User with this API key not found', 'code': 400}}\n",
      "\n",
      "ERROR: Failed to extract document 1/2: unknown_source\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2f76d5-fa4c-41f4-a9e2-72880bb59f34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
